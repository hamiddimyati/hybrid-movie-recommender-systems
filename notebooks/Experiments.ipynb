{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the implementation of the following recommender algorithms:\n",
    "\n",
    "- Content-Based Filtering\n",
    "- Item-Based Collaborative Filtering\n",
    "- User-Based Collaborative Filtering\n",
    "- Matrix Factorization Collaborative Filtering\n",
    "- Weighted Hybrid Filtering\n",
    "- Mixed Hybrid Filtering\n",
    "- Cascade Hybrid Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Objective\n",
    "\n",
    "    * To compare how each recommender algorithm perform in predicting ratings and recommending relevant items.\n",
    "\n",
    "* Environment\n",
    "\n",
    "    * The comparison is run on Google colab.\n",
    "        \n",
    "* Datasets\n",
    "        \n",
    "    * Movielens 100K.\n",
    "\n",
    "\n",
    "* Data split\n",
    "\n",
    "    * The data is split into train and test sets.\n",
    "    * The split ratios are 80-20 for train and test datasets.\n",
    "    * The splitting is done per user.\n",
    "\n",
    "\n",
    "* Evaluation metrics\n",
    "\n",
    "    * Ranking metrics:\n",
    "\n",
    "        * Precision@k.\n",
    "        * Recall@k.\n",
    "        * Normalized discounted cumulative gain@k (NDCG@k).\n",
    "\n",
    "    * Rating metrics:\n",
    "        * Root mean squared error (RMSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import feather\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100\n",
    "n_splits = 1\n",
    "col_split = 'item'\n",
    "n_samples = 100\n",
    "n_iter = 4\n",
    "col_eval = 'RMSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_DICT = {\n",
    "    'col_user':'userID',\n",
    "    'col_item':'itemID',\n",
    "    'col_rating':'rating',\n",
    "    'col_prediction':'prediction',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommender.content_based_recommender import train_content, predict_content\n",
    "from recommender.item_item_collab_recommender import train_item, predict_item\n",
    "from recommender.user_user_collab_recommender import train_user, predict_user\n",
    "from recommender.matrix_fact_collab_recommender import train_mf, predict_mf\n",
    "from recommender.weighted_hybrid_recommender import train_weighted, predict_weighted\n",
    "from recommender.mixed_hybrid_recommender import train_mixed, predict_mixed\n",
    "from recommender.cascade_hybrid_recommender import train_cascade, predict_cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = {\n",
    "    \"content\": lambda  data, catalog, params: train_content(data, catalog, params),\n",
    "    \"item-item\": lambda  data, catalog, params: train_item(data, catalog, params),\n",
    "    \"user-user\": lambda  data, catalog, params: train_user(data, catalog, params), \n",
    "    \"matrix-factorization\":  lambda data, catalog, params: train_mf(data, catalog, params),\n",
    "    \"weighted\": lambda  data, catalog, params: train_weighted(data, catalog, params),\n",
    "    \"mixed\": lambda  data, catalog, params: train_mixed(data, catalog, params),\n",
    "    \"cascade\": lambda  data, catalog, params: train_cascade(data, catalog, params),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = {\n",
    "    \"content\": lambda model, test, train: predict_content(model, test, train),\n",
    "    \"item-item\": lambda model, test, train: predict_item(model, test, train),\n",
    "    \"user-user\": lambda model, test, train: predict_user(model, test, train),\n",
    "    \"matrix-factorization\": lambda model, test, train: predict_mf(model,test, train),\n",
    "    \"weighted\": lambda model, test, train: predict_weighted(model, test, train),\n",
    "    \"mixed\": lambda model, test, train: predict_mixed(model, test, train),\n",
    "    \"cascade\": lambda model, test, train: predict_cascade(model, test, train),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(algo, rating_metrics, ranking_metrics, params):\n",
    "    summary = {\"Algo\": algo, **params}\n",
    "    if rating_metrics is None:\n",
    "        rating_metrics = {\n",
    "            \"RMSE\": np.nan,\n",
    "        }\n",
    "    if ranking_metrics is None:\n",
    "        ranking_metrics = {\n",
    "            \"nDCG@k\": np.nan,\n",
    "            \"Precision@k\": np.nan,\n",
    "            \"Recall@k\": np.nan,\n",
    "            \"F1@k\": np.nan,\n",
    "        }\n",
    "    summary.update(rating_metrics)\n",
    "    summary.update(ranking_metrics)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_params(df, algo):\n",
    "    grps = df.groupby(['Algo']).apply(lambda x: x.nlargest(1, col_eval))\n",
    "    return grps[grps['Algo'] == algo]['params'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.metric import rmse, ndcg_at_k, precision_at_k, recall_at_k\n",
    "from dataset.splitters import stratified_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_metrics(test, predictions):\n",
    "    return {\n",
    "        \"RMSE\": rmse(test, predictions, **COL_DICT),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_metrics(test, predictions, k):\n",
    "    precision = precision_at_k(test, predictions, k=k, **COL_DICT)\n",
    "    recall = recall_at_k(test, predictions, k=k, **COL_DICT)\n",
    "    return {\n",
    "        \"nDCG@k\": ndcg_at_k(test, predictions, k=k, **COL_DICT),\n",
    "        \"Precision@k\": precision,\n",
    "        \"Recall@k\": recall,\n",
    "        \"F1@k\": (2*precision*recall)/(precision+recall)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparamter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "from scipy.stats.distributions import uniform, randint\n",
    "from dataset.splitters import stratified_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_params = {\n",
    "    'alpha' : uniform(),\n",
    "    'l1_ratio': uniform()\n",
    "}\n",
    "\n",
    "weighted_params = {\n",
    "    'wght' : uniform(loc=0.2, scale=0.85)\n",
    "}\n",
    "\n",
    "cascade_params = {\n",
    "    'threshold': uniform(loc=0,scale=5)\n",
    "}\n",
    "\n",
    "mixed_params = {\n",
    "    'lmt' : randint(5,50) #(1,10)*5\n",
    "}\n",
    "\n",
    "hyper_params = {\n",
    "    \"matrix-factorization\": mf_params,\n",
    "    \"weighted\": weighted_params,\n",
    "    \"cascade\": cascade_params,\n",
    "    \"mixed\": mixed_params,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parmeterized_algorithms = [\"matrix-factorization\", \"weighted\", \"cascade\", \"mixed\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Movielens Sample: (5288, 4)\n",
      "\n",
      "Tuning matrix-factorization algorithm on Movielens Sample\n",
      "\n",
      "Using Parameters {'alpha': 0.5019584286159557, 'l1_ratio': 0.9096845931938514}\n",
      "\n",
      "Using Parameters {'alpha': 0.4289686294152538, 'l1_ratio': 0.6865587754478902}\n",
      "\n",
      "Using Parameters {'alpha': 0.4022425164972864, 'l1_ratio': 0.027845334735442484}\n",
      "\n",
      "Using Parameters {'alpha': 0.3905507270778187, 'l1_ratio': 0.5919920475925088}\n",
      "\n",
      "Tuning weighted algorithm on Movielens Sample\n",
      "\n",
      "Using Parameters {'wght': 1.0275380508522372, 'alpha': 0.5019584286159557, 'l1_ratio': 0.9096845931938514}\n",
      "4, 5, 6, 7, 8, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 32, 33, 39, 40, 42, 44, 45, 46, 50, 57, 58, 61, 63, 64, 65, 66, 67, 68, 71, 72, 74, 76, 77, 79, 80, 82, 84, 86, 89, 91, 94, 95, 96, 97, 100, 101, 103, 105, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 133, 135, 137, 139, 140, 141, 142, 144, 145, 148, 149, 152, 153, 155, 156, 159, 160, 162, 164, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 191, 192, 193, 195, 197, 198, 199, 200, 202, 204, 206, 207, 209, 210, 211, 212, 213, 217, 219, 220, 221, 222, 224, 226, 227, 228, 229, 230, 232, 233, 234, 235, 237, 239, 240, 243, 246, 247, 249, 254, 255, 256, 258, 261, 262, 263, 265, 266, 267, 268, 270, 274, 275, 276, 279, 282, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 297, 298, 302, 304, 305, 307, 308, 309, 310, 312, 313, 314, 317, 318, 319, 321, 322, 323, 325, 326, 328, 330, 331, 332, 334, 336, 337, 339, 340, 343, 344, 346, 347, 348, 350, 351, 352, 353, 354, 356, 357, 367, 368, 369, 371, 372, 373, 376, 377, 378, 380, 381, 382, 385, 387, 390, 391, 393, 394, 398, 401, 402, 404, 405, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 423, 424, 425, 427, 428, 429, 430, 432, 433, 434, 437, 438, 441, 445, 446, 447, 448, 451, 452, 453, 455, 457, 458, 460, 461, 462, 464, 465, 466, 467, 468, 469, 471, 472, 473, 474, 475, 477, 479, 480, 483, 485, 486, 487, 488, 489, 490, 492, 493, 494, 495, 500, 503, 505, 507, 509, 510, 512, 513, 514, 517, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 532, 534, 536, 537, 539, 541, 542, 543, 546, 551, 552, 553, 554, 555, 558, 559, 560, 561, 562, 563, 565, 566, 567, 570, 572, 573, 577, 579, 580, 582, 584, 586, 587, 588, 589, 590, 591, 592, 593, 594, 596, 599, 600, 601, 602, 603, 605, 606, 607, 608, 609, 610, \n",
      "Using Parameters {'wght': 0.7651361774452798, 'alpha': 0.5019584286159557, 'l1_ratio': 0.9096845931938514}\n",
      "4, 5, 6, 7, 8, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 32, 33, 39, 40, 42, 44, 45, 46, 50, 57, 58, 61, 63, 64, 65, 66, 67, 68, 71, 72, 74, 76, 77, 79, 80, 82, 84, 86, 89, 91, 94, 95, 96, 97, 100, 101, 103, 105, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 133, 135, 137, 139, 140, 141, 142, 144, 145, 148, 149, 152, 153, 155, 156, 159, 160, 162, 164, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 191, 192, 193, 195, 197, 198, 199, 200, 202, 204, 206, 207, 209, 210, 211, 212, 213, 217, 219, 220, 221, 222, 224, 226, 227, 228, 229, 230, 232, 233, 234, 235, 237, 239, 240, 243, 246, 247, 249, 254, 255, 256, 258, 261, 262, 263, 265, 266, 267, 268, 270, 274, 275, 276, 279, 282, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 297, 298, 302, 304, 305, 307, 308, 309, 310, 312, 313, 314, 317, 318, 319, 321, 322, 323, 325, 326, 328, 330, 331, 332, 334, 336, 337, 339, 340, 343, 344, 346, 347, 348, 350, 351, 352, 353, 354, 356, 357, 367, 368, 369, 371, 372, 373, 376, 377, 378, 380, 381, 382, 385, 387, 390, 391, 393, 394, 398, 401, 402, 404, 405, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 423, 424, 425, 427, 428, 429, 430, 432, 433, 434, 437, 438, 441, 445, 446, 447, 448, 451, 452, 453, 455, 457, 458, 460, 461, 462, 464, 465, 466, 467, 468, 469, 471, 472, 473, 474, 475, 477, 479, 480, 483, 485, 486, 487, 488, 489, 490, 492, 493, 494, 495, 500, 503, 505, 507, 509, 510, 512, 513, 514, 517, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 532, 534, 536, 537, 539, 541, 542, 543, 546, 551, 552, 553, 554, 555, 558, 559, 560, 561, 562, 563, 565, 566, 567, 570, 572, 573, 577, 579, 580, 582, 584, 586, 587, 588, 589, 590, 591, 592, 593, 594, 596, 599, 600, 601, 602, 603, 605, 606, 607, 608, 609, 610, \n",
      "Using Parameters {'wght': 0.503619312804398, 'alpha': 0.5019584286159557, 'l1_ratio': 0.9096845931938514}\n",
      "4, 5, 6, 7, 8, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 32, 33, 39, 40, 42, 44, 45, 46, 50, 57, 58, 61, 63, 64, 65, 66, 67, 68, 71, 72, 74, 76, 77, 79, 80, 82, 84, 86, 89, 91, 94, 95, 96, 97, 100, 101, 103, 105, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 133, 135, 137, 139, 140, 141, 142, 144, 145, 148, 149, 152, 153, 155, 156, 159, 160, 162, 164, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 191, 192, 193, 195, 197, 198, 199, 200, 202, 204, 206, 207, 209, 210, 211, 212, 213, 217, 219, 220, 221, 222, 224, 226, 227, 228, 229, 230, 232, 233, 234, 235, 237, 239, 240, 243, 246, 247, 249, 254, 255, 256, 258, 261, 262, 263, 265, 266, 267, 268, 270, 274, 275, 276, 279, 282, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 297, 298, 302, 304, 305, 307, 308, 309, 310, 312, 313, 314, 317, 318, 319, 321, 322, 323, 325, 326, 328, 330, 331, 332, 334, 336, 337, 339, 340, 343, 344, 346, 347, 348, 350, 351, 352, 353, 354, 356, 357, 367, 368, 369, 371, 372, 373, 376, 377, 378, 380, 381, 382, 385, 387, 390, 391, 393, 394, 398, 401, 402, 404, 405, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 423, 424, 425, 427, 428, 429, 430, 432, 433, 434, 437, 438, 441, 445, 446, 447, 448, 451, 452, 453, 455, 457, 458, 460, 461, 462, 464, 465, 466, 467, 468, 469, 471, 472, 473, 474, 475, 477, 479, 480, 483, 485, 486, 487, 488, 489, 490, 492, 493, 494, 495, 500, 503, 505, 507, 509, 510, 512, 513, 514, 517, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 532, 534, 536, 537, 539, 541, 542, 543, 546, 551, 552, 553, 554, 555, 558, 559, 560, 561, 562, 563, 565, 566, 567, 570, 572, 573, 577, 579, 580, 582, 584, 586, 587, 588, 589, 590, 591, 592, 593, 594, 596, 599, 600, 601, 602, 603, 605, 606, 607, 608, 609, 610, \n",
      "Using Parameters {'wght': 0.41036076420498724, 'alpha': 0.5019584286159557, 'l1_ratio': 0.9096845931938514}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4, 5, 6, 7, 8, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 32, 33, 39, 40, 42, 44, 45, 46, 50, 57, 58, 61, 63, 64, 65, 66, 67, 68, 71, 72, 74, 76, 77, 79, 80, 82, 84, 86, 89, 91, 94, 95, 96, 97, 100, 101, 103, 105, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 133, 135, 137, 139, 140, 141, 142, 144, 145, 148, 149, 152, 153, 155, 156, 159, 160, 162, 164, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 191, 192, 193, 195, 197, 198, 199, 200, 202, 204, 206, 207, 209, 210, 211, 212, 213, 217, 219, 220, 221, 222, 224, 226, 227, 228, 229, 230, 232, 233, 234, 235, 237, 239, 240, 243, 246, 247, 249, 254, 255, 256, 258, 261, 262, 263, 265, 266, 267, 268, 270, 274, 275, 276, 279, 282, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 297, 298, 302, 304, 305, 307, 308, 309, 310, 312, 313, 314, 317, 318, 319, 321, 322, 323, 325, 326, 328, 330, 331, 332, 334, 336, 337, 339, 340, 343, 344, 346, 347, 348, 350, 351, 352, 353, 354, 356, 357, 367, 368, 369, 371, 372, 373, 376, 377, 378, 380, 381, 382, 385, 387, 390, 391, 393, 394, 398, 401, 402, 404, 405, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 423, 424, 425, 427, 428, 429, 430, 432, 433, 434, 437, 438, 441, 445, 446, 447, 448, 451, 452, 453, 455, 457, 458, 460, 461, 462, 464, 465, 466, 467, 468, 469, 471, 472, 473, 474, 475, 477, 479, 480, 483, 485, 486, 487, 488, 489, 490, 492, 493, 494, 495, 500, 503, 505, 507, 509, 510, 512, 513, 514, 517, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 532, 534, 536, 537, 539, 541, 542, 543, 546, 551, 552, 553, 554, 555, 558, 559, 560, 561, 562, 563, 565, 566, 567, 570, 572, 573, 577, 579, 580, 582, 584, 586, 587, 588, 589, 590, 591, 592, 593, 594, 596, 599, 600, 601, 602, 603, 605, 606, 607, 608, 609, 610, \n",
      "Tuning cascade algorithm on Movielens Sample\n",
      "\n",
      "Using Parameters {'threshold': 4.670539458865781, 'alpha': 0.5019584286159557, 'l1_ratio': 0.9096845931938514}\n",
      "1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 253, 254, 255, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 279, 280, 282, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 312, 313, 314, 317, 318, 319, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 389, 390, 391, 392, 393, 394, 395, 398, 399, 400, 401, 402, 403, 404, 405, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 479, 480, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 536, 537, 538, 539, 540, 541, 542, 543, 544, 546, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 572, 573, 574, 577, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, \n",
      "Using Parameters {'threshold': 2.8106435923542255, 'alpha': 0.5019584286159557, 'l1_ratio': 0.9096845931938514}\n",
      "1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 253, 254, 255, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 279, 280, 282, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 312, 313, 314, 317, 318, 319, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 389, 390, 391, 392, 393, 394, 395, 398, 399, 400, 401, 402, 403, 404, 405, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 479, 480, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 536, 537, 538, 539, 540, 541, 542, 543, 544, 546, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 572, 573, 574, 577, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, \n",
      "Using Parameters {'threshold': 2.9634548554286386, 'alpha': 0.5019584286159557, 'l1_ratio': 0.9096845931938514}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 253, 254, 255, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 279, 280, 282, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 312, 313, 314, 317, 318, 319, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 389, 390, 391, 392, 393, 394, 395, 398, 399, 400, 401, 402, 403, 404, 405, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 479, 480, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 536, 537, 538, 539, 540, 541, 542, 543, 544, 546, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 572, 573, 574, 577, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, \n",
      "Using Parameters {'threshold': 3.973325187103445, 'alpha': 0.5019584286159557, 'l1_ratio': 0.9096845931938514}\n",
      "1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 253, 254, 255, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 279, 280, 282, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 312, 313, 314, 317, 318, 319, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 389, 390, 391, 392, 393, 394, 395, 398, 399, 400, 401, 402, 403, 404, 405, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 479, 480, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 536, 537, 538, 539, 540, 541, 542, 543, 544, 546, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 572, 573, 574, 577, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, \n",
      "Tuning mixed algorithm on Movielens Sample\n",
      "\n",
      "Using Parameters {'lmt': 26, 'alpha': 0.5019584286159557, 'l1_ratio': 0.9096845931938514}\n",
      "4, 5, 6, 7, 8, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 32, 33, 39, 40, 42, 44, 45, 46, 50, 57, 58, 61, 63, 64, 65, 66, 67, 68, 71, 72, 74, 76, 77, 79, 80, 82, 84, 86, 89, 91, 94, 95, 96, 97, 100, 101, 103, 105, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 133, 135, 137, 139, 140, 141, 142, 144, 145, 148, 149, 152, 153, 155, 156, 159, 160, 162, 164, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 191, 192, 193, 195, 197, 198, 199, 200, 202, 204, 206, 207, 209, 210, 211, 212, 213, 217, 219, 220, 221, 222, 224, 226, 227, 228, 229, 230, 232, 233, 234, 235, 237, 239, 240, 243, 246, 247, 249, 254, 255, 256, 258, 261, 262, 263, 265, 266, 267, 268, 270, 274, 275, 276, 279, 282, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 297, 298, 302, 304, 305, 307, 308, 309, 310, 312, 313, 314, 317, 318, 319, 321, 322, 323, 325, 326, 328, 330, 331, 332, 334, 336, 337, 339, 340, 343, 344, 346, 347, 348, 350, 351, 352, 353, 354, 356, 357, 367, 368, 369, 371, 372, 373, 376, 377, 378, 380, 381, 382, 385, 387, 390, 391, 393, 394, 398, 401, 402, 404, 405, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 423, 424, 425, 427, 428, 429, 430, 432, 433, 434, 437, 438, 441, 445, 446, 447, 448, 451, 452, 453, 455, 457, 458, 460, 461, 462, 464, 465, 466, 467, 468, 469, 471, 472, 473, 474, 475, 477, 479, 480, 483, 485, 486, 487, 488, 489, 490, 492, 493, 494, 495, 500, 503, 505, 507, 509, 510, 512, 513, 514, 517, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 532, 534, 536, 537, 539, 541, 542, 543, 546, 551, 552, 553, 554, 555, 558, 559, 560, 561, 562, 563, 565, 566, 567, 570, 572, 573, 577, 579, 580, 582, 584, 586, 587, 588, 589, 590, 591, 592, 593, 594, 596, 599, 600, 601, 602, 603, 605, 606, 607, 608, 609, 610, \n",
      "Using Parameters {'lmt': 35, 'alpha': 0.5019584286159557, 'l1_ratio': 0.9096845931938514}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4, 5, 6, 7, 8, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 32, 33, 39, 40, 42, 44, 45, 46, 50, 57, 58, 61, 63, 64, 65, 66, 67, 68, 71, 72, 74, 76, 77, 79, 80, 82, 84, 86, 89, 91, 94, 95, 96, 97, 100, 101, 103, 105, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 133, 135, 137, 139, 140, 141, 142, 144, 145, 148, 149, 152, 153, 155, 156, 159, 160, 162, 164, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 191, 192, 193, 195, 197, 198, 199, 200, 202, 204, 206, 207, 209, 210, 211, 212, 213, 217, 219, 220, 221, 222, 224, 226, 227, 228, 229, 230, 232, 233, 234, 235, 237, 239, 240, 243, 246, 247, 249, 254, 255, 256, 258, 261, 262, 263, 265, 266, 267, 268, 270, 274, 275, 276, 279, 282, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 297, 298, 302, 304, 305, 307, 308, 309, 310, 312, 313, 314, 317, 318, 319, 321, 322, 323, 325, 326, 328, 330, 331, 332, 334, 336, 337, 339, 340, 343, 344, 346, 347, 348, 350, 351, 352, 353, 354, 356, 357, 367, 368, 369, 371, 372, 373, 376, 377, 378, 380, 381, 382, 385, 387, 390, 391, 393, 394, 398, 401, 402, 404, 405, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 423, 424, 425, 427, 428, 429, 430, 432, 433, 434, 437, 438, 441, 445, 446, 447, 448, 451, 452, 453, 455, 457, 458, 460, 461, 462, 464, 465, 466, 467, 468, 469, 471, 472, 473, 474, 475, 477, 479, 480, 483, 485, 486, 487, 488, 489, 490, 492, 493, 494, 495, 500, 503, 505, 507, 509, 510, 512, 513, 514, 517, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 532, 534, 536, 537, 539, 541, 542, 543, 546, 551, 552, 553, 554, 555, 558, 559, 560, 561, 562, 563, 565, 566, 567, 570, 572, 573, 577, 579, 580, 582, 584, 586, 587, 588, 589, 590, 591, 592, 593, 594, 596, 599, 600, 601, 602, 603, 605, 606, 607, 608, 609, 610, \n",
      "Using Parameters {'lmt': 10, 'alpha': 0.5019584286159557, 'l1_ratio': 0.9096845931938514}\n",
      "4, 5, 6, 7, 8, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 32, 33, 39, 40, 42, 44, 45, 46, 50, 57, 58, 61, 63, 64, 65, 66, 67, 68, 71, 72, 74, 76, 77, 79, 80, 82, 84, 86, 89, 91, 94, 95, 96, 97, 100, 101, 103, 105, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 133, 135, 137, 139, 140, 141, 142, 144, 145, 148, 149, 152, 153, 155, 156, 159, 160, 162, 164, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 191, 192, 193, 195, 197, 198, 199, 200, 202, 204, 206, 207, 209, 210, 211, 212, 213, 217, 219, 220, 221, 222, 224, 226, 227, 228, 229, 230, 232, 233, 234, 235, 237, 239, 240, 243, 246, 247, 249, 254, 255, 256, 258, 261, 262, 263, 265, 266, 267, 268, 270, 274, 275, 276, 279, 282, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 297, 298, 302, 304, 305, 307, 308, 309, 310, 312, 313, 314, 317, 318, 319, 321, 322, 323, 325, 326, 328, 330, 331, 332, 334, 336, 337, 339, 340, 343, 344, 346, 347, 348, 350, 351, 352, 353, 354, 356, 357, 367, 368, 369, 371, 372, 373, 376, 377, 378, 380, 381, 382, 385, 387, 390, 391, 393, 394, 398, 401, 402, 404, 405, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 423, 424, 425, 427, 428, 429, 430, 432, 433, 434, 437, 438, 441, 445, 446, 447, 448, 451, 452, 453, 455, 457, 458, 460, 461, 462, 464, 465, 466, 467, 468, 469, 471, 472, 473, 474, 475, 477, 479, 480, 483, 485, 486, 487, 488, 489, 490, 492, 493, 494, 495, 500, 503, 505, 507, 509, 510, 512, 513, 514, 517, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 532, 534, 536, 537, 539, 541, 542, 543, 546, 551, 552, 553, 554, 555, 558, 559, 560, 561, 562, 563, 565, 566, 567, 570, 572, 573, 577, 579, 580, 582, 584, 586, 587, 588, 589, 590, 591, 592, 593, 594, 596, 599, 600, 601, 602, 603, 605, 606, 607, 608, 609, 610, \n",
      "Using Parameters {'lmt': 42, 'alpha': 0.5019584286159557, 'l1_ratio': 0.9096845931938514}\n",
      "4, 5, 6, 7, 8, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 32, 33, 39, 40, 42, 44, 45, 46, 50, 57, 58, 61, 63, 64, 65, 66, 67, 68, 71, 72, 74, 76, 77, 79, 80, 82, 84, 86, 89, 91, 94, 95, 96, 97, 100, 101, 103, 105, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 133, 135, 137, 139, 140, 141, 142, 144, 145, 148, 149, 152, 153, 155, 156, 159, 160, 162, 164, 165, 166, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 191, 192, 193, 195, 197, 198, 199, 200, 202, 204, 206, 207, 209, 210, 211, 212, 213, 217, 219, 220, 221, 222, 224, 226, 227, 228, 229, 230, 232, 233, 234, 235, 237, 239, 240, 243, 246, 247, 249, 254, 255, 256, 258, 261, 262, 263, 265, 266, 267, 268, 270, 274, 275, 276, 279, 282, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 297, 298, 302, 304, 305, 307, 308, 309, 310, 312, 313, 314, 317, 318, 319, 321, 322, 323, 325, 326, 328, 330, 331, 332, 334, 336, 337, 339, 340, 343, 344, 346, 347, 348, 350, 351, 352, 353, 354, 356, 357, 367, 368, 369, 371, 372, 373, 376, 377, 378, 380, 381, 382, 385, 387, 390, 391, 393, 394, 398, 401, 402, 404, 405, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 423, 424, 425, 427, 428, 429, 430, 432, 433, 434, 437, 438, 441, 445, 446, 447, 448, 451, 452, 453, 455, 457, 458, 460, 461, 462, 464, 465, 466, 467, 468, 469, 471, 472, 473, 474, 475, 477, 479, 480, 483, 485, 486, 487, 488, 489, 490, 492, 493, 494, 495, 500, 503, 505, 507, 509, 510, 512, 513, 514, 517, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 532, 534, 536, 537, 539, 541, 542, 543, 546, 551, 552, 553, 554, 555, 558, 559, 560, 561, 562, 563, 565, 566, 567, 570, 572, 573, 577, 579, 580, 582, 584, 586, 587, 588, 589, 590, 591, 592, 593, 594, 596, 599, 600, 601, 602, 603, 605, 606, 607, 608, 609, 610, \n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# For each  algorithm, a recommender is evaluated. \n",
    "cols = [\"Algo\", \"params\", \"RMSE\", \"nDCG@k\", \"Precision@k\", \"Recall@k\", \"F1@k\"]\n",
    "df_results = pd.DataFrame(columns=cols)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/ratings.csv', header=0,\n",
    "    names=['userID', 'itemID', 'rating', 'timestamp']\n",
    ")\n",
    "\n",
    "# take a random sample of the dataset to speed up cross validation\n",
    "df = df[df['itemID'].isin(random.choices(df['itemID'].values,k=n_samples))]\n",
    "\n",
    "print(f\"Size of Movielens Sample: {df.shape}\")\n",
    "\n",
    "# Split the dataset\n",
    "train, test  = stratified_split(df, filter_by=col_split, min_rating=1, ratio=0.8)\n",
    "\n",
    "# remove movies with less than min_rating from the catalog\n",
    "catalog = pd.read_feather('data/content_movie.ftr')\n",
    "catalog = catalog[catalog['movieId'].isin(train.itemID)].reset_index()\n",
    "\n",
    "# Loop through the algos\n",
    "for algo in parmeterized_algorithms:\n",
    "    print(f\"\\nTuning {algo} algorithm on Movielens Sample\")\n",
    "    \n",
    "    # get model parameters\n",
    "    model_hyper_params = hyper_params[algo]\n",
    "    \n",
    "    param_list = list(ParameterSampler(model_hyper_params, n_iter=n_iter))\n",
    "    \n",
    "    for model_param in param_list:\n",
    "        \n",
    "        if algo in ['weighted', 'cascade', 'mixed']:\n",
    "            model_param =  {**model_param, **best_params(df_results, 'matrix-factorization')}\n",
    "        \n",
    "        print(f\"\\nUsing Parameters {model_param}\")\n",
    "        \n",
    "        # Train the model\n",
    "        model = trainer[algo](train, catalog, model_param)\n",
    "\n",
    "        # Predict and evaluate\n",
    "        preds = predictor[algo](model, test, train)\n",
    "\n",
    "        # calculate metrics\n",
    "        ratings = rating_metrics(test, preds)\n",
    "        rankings = ranking_metrics(test, preds, k) \n",
    "\n",
    "        # Record results\n",
    "        summary = generate_summary(algo, ratings, rankings, params={'params':model_param})\n",
    "\n",
    "        df_results.loc[df_results.shape[0] + 1] = summary\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algo</th>\n",
       "      <th>params</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>nDCG@k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>F1@k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>matrix-factorization</td>\n",
       "      <td>{'alpha': 0.5019584286159557, 'l1_ratio': 0.90...</td>\n",
       "      <td>3.583203</td>\n",
       "      <td>0.315251</td>\n",
       "      <td>0.025939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>matrix-factorization</td>\n",
       "      <td>{'alpha': 0.4289686294152538, 'l1_ratio': 0.68...</td>\n",
       "      <td>3.578310</td>\n",
       "      <td>0.329407</td>\n",
       "      <td>0.025939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>matrix-factorization</td>\n",
       "      <td>{'alpha': 0.4022425164972864, 'l1_ratio': 0.02...</td>\n",
       "      <td>3.573751</td>\n",
       "      <td>0.329150</td>\n",
       "      <td>0.025939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>matrix-factorization</td>\n",
       "      <td>{'alpha': 0.3905507270778187, 'l1_ratio': 0.59...</td>\n",
       "      <td>3.579297</td>\n",
       "      <td>0.325973</td>\n",
       "      <td>0.025939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weighted</td>\n",
       "      <td>{'wght': 1.0275380508522372, 'alpha': 0.501958...</td>\n",
       "      <td>3.729382</td>\n",
       "      <td>0.313480</td>\n",
       "      <td>0.027033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted</td>\n",
       "      <td>{'wght': 0.7651361774452798, 'alpha': 0.501958...</td>\n",
       "      <td>2.849484</td>\n",
       "      <td>0.329704</td>\n",
       "      <td>0.027033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weighted</td>\n",
       "      <td>{'wght': 0.503619312804398, 'alpha': 0.5019584...</td>\n",
       "      <td>2.023210</td>\n",
       "      <td>0.334513</td>\n",
       "      <td>0.027033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weighted</td>\n",
       "      <td>{'wght': 0.41036076420498724, 'alpha': 0.50195...</td>\n",
       "      <td>1.752620</td>\n",
       "      <td>0.334867</td>\n",
       "      <td>0.027033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cascade</td>\n",
       "      <td>{'threshold': 4.670539458865781, 'alpha': 0.50...</td>\n",
       "      <td>3.655255</td>\n",
       "      <td>0.274592</td>\n",
       "      <td>0.025939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cascade</td>\n",
       "      <td>{'threshold': 2.8106435923542255, 'alpha': 0.5...</td>\n",
       "      <td>2.096875</td>\n",
       "      <td>0.272622</td>\n",
       "      <td>0.025939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cascade</td>\n",
       "      <td>{'threshold': 2.9634548554286386, 'alpha': 0.5...</td>\n",
       "      <td>2.156926</td>\n",
       "      <td>0.254413</td>\n",
       "      <td>0.025939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cascade</td>\n",
       "      <td>{'threshold': 3.973325187103445, 'alpha': 0.50...</td>\n",
       "      <td>2.992951</td>\n",
       "      <td>0.256763</td>\n",
       "      <td>0.025939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mixed</td>\n",
       "      <td>{'lmt': 26, 'alpha': 0.5019584286159557, 'l1_r...</td>\n",
       "      <td>3.016650</td>\n",
       "      <td>0.305299</td>\n",
       "      <td>0.027033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mixed</td>\n",
       "      <td>{'lmt': 35, 'alpha': 0.5019584286159557, 'l1_r...</td>\n",
       "      <td>2.738135</td>\n",
       "      <td>0.302766</td>\n",
       "      <td>0.027033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mixed</td>\n",
       "      <td>{'lmt': 10, 'alpha': 0.5019584286159557, 'l1_r...</td>\n",
       "      <td>3.366836</td>\n",
       "      <td>0.310265</td>\n",
       "      <td>0.027033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mixed</td>\n",
       "      <td>{'lmt': 42, 'alpha': 0.5019584286159557, 'l1_r...</td>\n",
       "      <td>2.548756</td>\n",
       "      <td>0.298869</td>\n",
       "      <td>0.027033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Algo                                             params  \\\n",
       "1   matrix-factorization  {'alpha': 0.5019584286159557, 'l1_ratio': 0.90...   \n",
       "2   matrix-factorization  {'alpha': 0.4289686294152538, 'l1_ratio': 0.68...   \n",
       "3   matrix-factorization  {'alpha': 0.4022425164972864, 'l1_ratio': 0.02...   \n",
       "4   matrix-factorization  {'alpha': 0.3905507270778187, 'l1_ratio': 0.59...   \n",
       "5               weighted  {'wght': 1.0275380508522372, 'alpha': 0.501958...   \n",
       "6               weighted  {'wght': 0.7651361774452798, 'alpha': 0.501958...   \n",
       "7               weighted  {'wght': 0.503619312804398, 'alpha': 0.5019584...   \n",
       "8               weighted  {'wght': 0.41036076420498724, 'alpha': 0.50195...   \n",
       "9                cascade  {'threshold': 4.670539458865781, 'alpha': 0.50...   \n",
       "10               cascade  {'threshold': 2.8106435923542255, 'alpha': 0.5...   \n",
       "11               cascade  {'threshold': 2.9634548554286386, 'alpha': 0.5...   \n",
       "12               cascade  {'threshold': 3.973325187103445, 'alpha': 0.50...   \n",
       "13                 mixed  {'lmt': 26, 'alpha': 0.5019584286159557, 'l1_r...   \n",
       "14                 mixed  {'lmt': 35, 'alpha': 0.5019584286159557, 'l1_r...   \n",
       "15                 mixed  {'lmt': 10, 'alpha': 0.5019584286159557, 'l1_r...   \n",
       "16                 mixed  {'lmt': 42, 'alpha': 0.5019584286159557, 'l1_r...   \n",
       "\n",
       "        RMSE    nDCG@k  Precision@k  Recall@k      F1@k  \n",
       "1   3.583203  0.315251     0.025939       1.0  0.050567  \n",
       "2   3.578310  0.329407     0.025939       1.0  0.050567  \n",
       "3   3.573751  0.329150     0.025939       1.0  0.050567  \n",
       "4   3.579297  0.325973     0.025939       1.0  0.050567  \n",
       "5   3.729382  0.313480     0.027033       1.0  0.052643  \n",
       "6   2.849484  0.329704     0.027033       1.0  0.052643  \n",
       "7   2.023210  0.334513     0.027033       1.0  0.052643  \n",
       "8   1.752620  0.334867     0.027033       1.0  0.052643  \n",
       "9   3.655255  0.274592     0.025939       1.0  0.050567  \n",
       "10  2.096875  0.272622     0.025939       1.0  0.050567  \n",
       "11  2.156926  0.254413     0.025939       1.0  0.050567  \n",
       "12  2.992951  0.256763     0.025939       1.0  0.050567  \n",
       "13  3.016650  0.305299     0.027033       1.0  0.052643  \n",
       "14  2.738135  0.302766     0.027033       1.0  0.052643  \n",
       "15  3.366836  0.310265     0.027033       1.0  0.052643  \n",
       "16  2.548756  0.298869     0.027033       1.0  0.052643  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algo</th>\n",
       "      <th>params</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>nDCG@k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>F1@k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>matrix-factorization</td>\n",
       "      <td>{'alpha': 0.5019584286159557, 'l1_ratio': 0.90...</td>\n",
       "      <td>3.583203</td>\n",
       "      <td>0.315251</td>\n",
       "      <td>0.025939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>matrix-factorization</td>\n",
       "      <td>{'alpha': 0.4289686294152538, 'l1_ratio': 0.68...</td>\n",
       "      <td>3.578310</td>\n",
       "      <td>0.329407</td>\n",
       "      <td>0.025939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>matrix-factorization</td>\n",
       "      <td>{'alpha': 0.4022425164972864, 'l1_ratio': 0.02...</td>\n",
       "      <td>3.573751</td>\n",
       "      <td>0.329150</td>\n",
       "      <td>0.025939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>matrix-factorization</td>\n",
       "      <td>{'alpha': 0.3905507270778187, 'l1_ratio': 0.59...</td>\n",
       "      <td>3.579297</td>\n",
       "      <td>0.325973</td>\n",
       "      <td>0.025939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weighted</td>\n",
       "      <td>{'wght': 1.0275380508522372, 'alpha': 0.501958...</td>\n",
       "      <td>3.729382</td>\n",
       "      <td>0.313480</td>\n",
       "      <td>0.027033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted</td>\n",
       "      <td>{'wght': 0.7651361774452798, 'alpha': 0.501958...</td>\n",
       "      <td>2.849484</td>\n",
       "      <td>0.329704</td>\n",
       "      <td>0.027033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weighted</td>\n",
       "      <td>{'wght': 0.503619312804398, 'alpha': 0.5019584...</td>\n",
       "      <td>2.023210</td>\n",
       "      <td>0.334513</td>\n",
       "      <td>0.027033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weighted</td>\n",
       "      <td>{'wght': 0.41036076420498724, 'alpha': 0.50195...</td>\n",
       "      <td>1.752620</td>\n",
       "      <td>0.334867</td>\n",
       "      <td>0.027033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cascade</td>\n",
       "      <td>{'threshold': 4.670539458865781, 'alpha': 0.50...</td>\n",
       "      <td>3.655255</td>\n",
       "      <td>0.274592</td>\n",
       "      <td>0.025939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cascade</td>\n",
       "      <td>{'threshold': 2.8106435923542255, 'alpha': 0.5...</td>\n",
       "      <td>2.096875</td>\n",
       "      <td>0.272622</td>\n",
       "      <td>0.025939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cascade</td>\n",
       "      <td>{'threshold': 2.9634548554286386, 'alpha': 0.5...</td>\n",
       "      <td>2.156926</td>\n",
       "      <td>0.254413</td>\n",
       "      <td>0.025939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cascade</td>\n",
       "      <td>{'threshold': 3.973325187103445, 'alpha': 0.50...</td>\n",
       "      <td>2.992951</td>\n",
       "      <td>0.256763</td>\n",
       "      <td>0.025939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mixed</td>\n",
       "      <td>{'lmt': 26, 'alpha': 0.5019584286159557, 'l1_r...</td>\n",
       "      <td>3.016650</td>\n",
       "      <td>0.305299</td>\n",
       "      <td>0.027033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mixed</td>\n",
       "      <td>{'lmt': 35, 'alpha': 0.5019584286159557, 'l1_r...</td>\n",
       "      <td>2.738135</td>\n",
       "      <td>0.302766</td>\n",
       "      <td>0.027033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mixed</td>\n",
       "      <td>{'lmt': 10, 'alpha': 0.5019584286159557, 'l1_r...</td>\n",
       "      <td>3.366836</td>\n",
       "      <td>0.310265</td>\n",
       "      <td>0.027033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mixed</td>\n",
       "      <td>{'lmt': 42, 'alpha': 0.5019584286159557, 'l1_r...</td>\n",
       "      <td>2.548756</td>\n",
       "      <td>0.298869</td>\n",
       "      <td>0.027033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Algo                                             params  \\\n",
       "1   matrix-factorization  {'alpha': 0.5019584286159557, 'l1_ratio': 0.90...   \n",
       "2   matrix-factorization  {'alpha': 0.4289686294152538, 'l1_ratio': 0.68...   \n",
       "3   matrix-factorization  {'alpha': 0.4022425164972864, 'l1_ratio': 0.02...   \n",
       "4   matrix-factorization  {'alpha': 0.3905507270778187, 'l1_ratio': 0.59...   \n",
       "5               weighted  {'wght': 1.0275380508522372, 'alpha': 0.501958...   \n",
       "6               weighted  {'wght': 0.7651361774452798, 'alpha': 0.501958...   \n",
       "7               weighted  {'wght': 0.503619312804398, 'alpha': 0.5019584...   \n",
       "8               weighted  {'wght': 0.41036076420498724, 'alpha': 0.50195...   \n",
       "9                cascade  {'threshold': 4.670539458865781, 'alpha': 0.50...   \n",
       "10               cascade  {'threshold': 2.8106435923542255, 'alpha': 0.5...   \n",
       "11               cascade  {'threshold': 2.9634548554286386, 'alpha': 0.5...   \n",
       "12               cascade  {'threshold': 3.973325187103445, 'alpha': 0.50...   \n",
       "13                 mixed  {'lmt': 26, 'alpha': 0.5019584286159557, 'l1_r...   \n",
       "14                 mixed  {'lmt': 35, 'alpha': 0.5019584286159557, 'l1_r...   \n",
       "15                 mixed  {'lmt': 10, 'alpha': 0.5019584286159557, 'l1_r...   \n",
       "16                 mixed  {'lmt': 42, 'alpha': 0.5019584286159557, 'l1_r...   \n",
       "\n",
       "        RMSE    nDCG@k  Precision@k  Recall@k      F1@k  \n",
       "1   3.583203  0.315251     0.025939       1.0  0.050567  \n",
       "2   3.578310  0.329407     0.025939       1.0  0.050567  \n",
       "3   3.573751  0.329150     0.025939       1.0  0.050567  \n",
       "4   3.579297  0.325973     0.025939       1.0  0.050567  \n",
       "5   3.729382  0.313480     0.027033       1.0  0.052643  \n",
       "6   2.849484  0.329704     0.027033       1.0  0.052643  \n",
       "7   2.023210  0.334513     0.027033       1.0  0.052643  \n",
       "8   1.752620  0.334867     0.027033       1.0  0.052643  \n",
       "9   3.655255  0.274592     0.025939       1.0  0.050567  \n",
       "10  2.096875  0.272622     0.025939       1.0  0.050567  \n",
       "11  2.156926  0.254413     0.025939       1.0  0.050567  \n",
       "12  2.992951  0.256763     0.025939       1.0  0.050567  \n",
       "13  3.016650  0.305299     0.027033       1.0  0.052643  \n",
       "14  2.738135  0.302766     0.027033       1.0  0.052643  \n",
       "15  3.366836  0.310265     0.027033       1.0  0.052643  \n",
       "16  2.548756  0.298869     0.027033       1.0  0.052643  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_mf = best_params(df_results, 'matrix-factorization')\n",
    "params_weighted = {**best_params(df_results, 'weighted'), **best_params(df_results, 'matrix-factorization')}\n",
    "params_cascade = {**best_params(df_results, 'cascade'), **best_params(df_results, 'matrix-factorization')}\n",
    "params_mixed = {**best_params(df_results, 'mixed'),**best_params(df_results, 'matrix-factorization')}\n",
    "\n",
    "params = {\n",
    "    \"content\": {},\n",
    "    \"item-item\": {},\n",
    "    \"user-user\": {},\n",
    "    \"matrix-factorization\": params_mf,\n",
    "    \"weighted\": params_weighted,\n",
    "    \"cascade\": params_cascade,\n",
    "    \"mixed\": params_mixed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': {},\n",
       " 'item-item': {},\n",
       " 'user-user': {},\n",
       " 'matrix-factorization': {'alpha': 0.5019584286159557,\n",
       "  'l1_ratio': 0.9096845931938514},\n",
       " 'weighted': {'wght': 1.0275380508522372,\n",
       "  'alpha': 0.5019584286159557,\n",
       "  'l1_ratio': 0.9096845931938514},\n",
       " 'cascade': {'threshold': 4.670539458865781,\n",
       "  'alpha': 0.5019584286159557,\n",
       "  'l1_ratio': 0.9096845931938514},\n",
       " 'mixed': {'lmt': 10,\n",
       "  'alpha': 0.5019584286159557,\n",
       "  'l1_ratio': 0.9096845931938514}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\"content\", \"item-item\", \"matrix-factorization\", \"weighted\", \"mixed\", \"cascade\"] #[\"content\", \"item-item\", \"user-user\", \"matrix-factorization\", \"weighted\", \"mixed\", \"cascade\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Movielens: (100836, 4)\n",
      "Doing Fold 1/1\n",
      "\n",
      "Computing content algorithm on Movielens\n",
      "2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, \n",
      "Computing item-item algorithm on Movielens\n",
      "2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, \n",
      "Computing matrix-factorization algorithm on Movielens\n",
      "\n",
      "Computing weighted algorithm on Movielens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, \n",
      "Computing mixed algorithm on Movielens\n",
      "2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, \n",
      "Computing cascade algorithm on Movielens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, \n",
      "Wall time: 31min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# For each  algorithm, a recommender is evaluated. \n",
    "cols = [\"Algo\",\"Fold\", \"K\", \"RMSE\", \"nDCG@k\", \"Precision@k\", \"Recall@k\", \"F1@k\"]\n",
    "df_results = pd.DataFrame(columns=cols)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/ratings.csv', header=0,\n",
    "    names=['userID', 'itemID', 'rating', 'timestamp']\n",
    ")\n",
    "\n",
    "print(f\"Size of Movielens: {df.shape}\")\n",
    "\n",
    "for i in range(n_splits):\n",
    "    \n",
    "    print(f\"Doing Fold {i+1}/{n_splits}\")\n",
    "    \n",
    "    # Split the dataset\n",
    "    train, test  = stratified_split(df, filter_by=col_split, min_rating=1, ratio=0.8)\n",
    "\n",
    "    # remove movies with less than min_rating from the catalog\n",
    "    catalog = pd.read_feather('data/content_movie.ftr')\n",
    "    catalog = catalog[catalog['movieId'].isin(train.itemID)].reset_index()\n",
    "\n",
    "    # Loop through the algos\n",
    "    for algo in algorithms:\n",
    "        print(f\"\\nComputing {algo} algorithm on Movielens\")\n",
    "\n",
    "        # get the parameters\n",
    "        model_params  = params[algo]\n",
    "\n",
    "        # Train the model\n",
    "        model = trainer[algo](train, catalog, model_params)\n",
    "\n",
    "        # Predict and evaluate\n",
    "        preds = predictor[algo](model, test, train)\n",
    "\n",
    "        # calculate metrics\n",
    "        ratings = rating_metrics(test, preds)\n",
    "        rankings = ranking_metrics(test, preds, k) \n",
    "        \n",
    "        # Record results\n",
    "        summary = generate_summary(algo, ratings, rankings, params={'Fold':i+1, 'K':k})\n",
    "\n",
    "        df_results.loc[df_results.shape[0] + 1] = summary\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algo</th>\n",
       "      <th>Fold</th>\n",
       "      <th>K</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>nDCG@k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>F1@k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.911782</td>\n",
       "      <td>0.050146</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>0.011460</td>\n",
       "      <td>0.006278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item-item</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.916321</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>matrix-factorization</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>3.171938</td>\n",
       "      <td>0.519016</td>\n",
       "      <td>0.093251</td>\n",
       "      <td>0.464531</td>\n",
       "      <td>0.155322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>3.248229</td>\n",
       "      <td>0.516927</td>\n",
       "      <td>0.093020</td>\n",
       "      <td>0.456799</td>\n",
       "      <td>0.154565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mixed</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>3.168481</td>\n",
       "      <td>0.364352</td>\n",
       "      <td>0.090759</td>\n",
       "      <td>0.446430</td>\n",
       "      <td>0.150850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cascade</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>3.631921</td>\n",
       "      <td>0.054026</td>\n",
       "      <td>0.004389</td>\n",
       "      <td>0.010546</td>\n",
       "      <td>0.006199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Algo Fold    K      RMSE    nDCG@k  Precision@k  Recall@k  \\\n",
       "1               content    1  100  0.911782  0.050146     0.004323  0.011460   \n",
       "2             item-item    1  100  0.916321  0.000995     0.000066  0.000029   \n",
       "3  matrix-factorization    1  100  3.171938  0.519016     0.093251  0.464531   \n",
       "4              weighted    1  100  3.248229  0.516927     0.093020  0.456799   \n",
       "5                 mixed    1  100  3.168481  0.364352     0.090759  0.446430   \n",
       "6               cascade    1  100  3.631921  0.054026     0.004389  0.010546   \n",
       "\n",
       "       F1@k  \n",
       "1  0.006278  \n",
       "2  0.000040  \n",
       "3  0.155322  \n",
       "4  0.154565  \n",
       "5  0.150850  \n",
       "6  0.006199  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
